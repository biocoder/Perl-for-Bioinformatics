=head1 NAME

 _            ____  _   _    _          _            
| |_ __   ___|  _ \| \ | |  / \   _ __ (_)_ __   ___ 
| | '_ \ / __| |_) |  \| | / _ \ | '_ \| | '_ \ / _ \
| | | | | (__|  _ <| |\  |/ ___ \| |_) | | |_) |  __/
|_|_| |_|\___|_| \_|_| \_/_/   \_| .__/|_| .__/ \___|
                                 |_|     |_|         

=head1 SYNOPSIS

lncRNApipe is a reference annotation based automated pipeline to identify non-coding RNAs, both known and novel from RNA-Seq reads. It takes FASTQ / FASTA reads as input, trims reads, assembles transcripts, and identifies any possible known and novel ncRNAs, categorizes them into 5 catgories: Long intergenic lncRNAs (B<I<LincRNAs>>), Intronic contained lncRNAs (B<I<Incs>>), Partially overlapping lncRNAs (B<I<Poncs>>), Completely overlapping lncRNAs (B<I<Concs>>) and Exonic overlaps (B<I<LncRNAs with sense or antisense overlap with reference exon>>) and annotates the novel ncRNAs, where possible.

See complete description: 

 perldoc lncRNApipe

Examples:

View this documentation:

 perl lncRNApipe --h

Run the complete pipeline from the configuration file C<< params.yaml >>:

 perl lncRNApipe --conf params.yaml

Run the complete pipeline on your local cluster's head node using the configuration file C<< params.yaml >> and do not wait for user confirmation of job IDs:

 perl lncRNApipe --conf params.yaml --dont-wait

Run the B<I<identification stage>> of the pipeline through command-line options without mentioning the configuration file C<< params.yaml >>:

 perl lncRNApipe --run /data/lncRNApipe/ \
                 --cuffcmp '-r annotation.gtf -s genome.fa transcripts1.gtf transcripts2.gtf' \
                 --cat-ncRNAs '-sample-names "M1,M2" -ov 80 -fpkm 2 -len 200 -max-len 10000 -min-exons 1 -antisense" \
                 --get-uq-feat '-sf known_lncRNAs.bed' \
                 --fetch-seq '-db mm10' \
                 --cpc \
                 --rna \
                 --inf &> lncRNApipe.run.log

=head1 CITATION

B<Assessment of Histone Tail Modifications and Transcriptional Profiling During Colon Cancer Progression Reveals a Global Decrease in H3K4me3 Activity> Karen Triff; Mathew W McLean; Kranti Konganti; Jiahui Pang; Evelyn Callaway; Beiyan Zhou; Ivan Ivanov; Robert S. Chapkin B<I<Molecular Basis of Disease 2017>>

=head1 INSTALLATION

lncRNApipe was developed in Linux environment and can be installed on UNIX based machines. If it is a 64-bit machine, all required prerequisites are sandboxed with the software and taken care of, which should run in most instances. lncRNApipe will attempt to find any available prerequisites on your machine and will default to them before using sandboxed binaries. All you need to do is run the following command to install the pipeline and all of its required dependencies:
 
 cd /change/into/my/preferred/path/of/installation
 curl -Ok https://raw.githubusercontent.com/biocoder/Perl-for-Bioinformatics/master/NGS-Utils/lncRNApipe
 perl lncRNApipe --setup

If you are on a 32-bit machine, run the same command as shown above, and lncRNApipe will let you know, which tools must to be installed and be available in your C<< $PATH >>.

In any case, the setup process will prompt you to specify whether or not you want to install B<I<BioPerl>>.

If the setup process fails due to compiler issues, or if any Perl module installation fails, try setting different compiler specific to your machine state with the following command:

Example (Using C<< g++ >> as the compiler):

 perl lncRNApipe --setup --setup-compiler CC=g++

B<SEE CAVEATS SECTION BELOW BEFORE YOU PROCEED TO TEST THE SOFTWARE INSTALLATION.>

=head1 TEST SOFTWARE INSTALLATION

Once you have finished installing, you can do a test run with the included data set to see if the software was installed and working properly. The test data and annotation was downloaded from L<EBI tutorial|http://www.ebi.ac.uk/training/online/course/ebi-next-generation-sequencing-practical-course/rna-sequencing/rna-seq-analysis-transcriptome> and subsetted to 25,000 reads. The known ncRNA information in GTF format was downloaded using Table Browser from L<NONCODE|http://noncode.org/cgi-bin/hgTables?hgsid=1488803&clade=vertebrate&org=Zebrafish&db=danRer10&hgta_group=genes&hgta_track=NONCODE2016RNA> database. The reference genome and indices are limited to chromosome 12.

To prepare the C<< params.yaml >> specific to your UNIX path, change into the directory where you installed B<lncRNApipe> and do:

 a=`pwd`"/"; sed "s@\/data.*\/lncRNApipe-test@$a\/lncRNApipe-test@g" params.yaml > lncRNApipe-test/params.test.yaml

The above command will replace all the UNIX paths in the file C<< params.yaml >> to the UNIX paths specific to your machine. Then, edit the file C<< params.test.yaml >> with appropriate values for C<< CPUs: >>, C<< scheduler: >>, C<< batchSubCmd: >>, C<< schedulerOpts: >> and / or C<< clusterOpts: >>. 

Finally, run the pipeline on the test data. If you are running the job on a cluster, do:

 perl lncRNApipe --conf lncRNApipe-test/params.test.yaml --dont-wait

If you are running the pipeline on your local workstation, do:

 perl lncRNApipe --conf lncRNApipe-test/params.test.yaml

After the pipeline finishes, you should see C<< passed >> in all status code files.

C<< lncRNApipe-test/run/trimmomatic/status.log >>
 
 lncRNApipe: AutoGenJobTime=Tue_Jan_26_10:20:14_2016 Run=1uzk7yVoHMcph AutoGenSampleName=run_1uzk7yVoHMcph.6h_rep_1 Trimmomatic run has passed.
 lncRNApipe: AutoGenJobTime=Tue_Jan_26_10:20:13_2016 Run=1uzk7yVoHMcph AutoGenSampleName=run_1uzk7yVoHMcph.2cells_rep_1 Trimmomatic run has passed.

C<< lncRNApipe-test/run/tophat/status.log >>
 
 lncRNApipe: AutoGenJobTime=Tue_Jan_26_10:20:14_2016 Run=1uzk7yVoHMcph AutoGenSampleName=run_1uzk7yVoHMcph.6h_rep_1 Tophat run has passed.
 lncRNApipe: AutoGenJobTime=Tue_Jan_26_10:20:13_2016 Run=1uzk7yVoHMcph AutoGenSampleName=run_1uzk7yVoHMcph.2cells_rep_1 Tophat run has passed.

C<< lncRNApipe-test/run/cufflinks/status.log >>

 lncRNApipe: AutoGenJobTime=Tue_Jan_26_10:20:14_2016 Run=1uzk7yVoHMcph AutoGenSampleName=run_1uzk7yVoHMcph.6h Cufflinks run has passed.
 lncRNApipe: AutoGenJobTime=Tue_Jan_26_10:20:13_2016 Run=1uzk7yVoHMcph AutoGenSampleName=run_1uzk7yVoHMcph.2cells Cufflinks run has passed.

C<< lncRNApipe-test/run/cufflinks/lncRNApipe_afterCufflinks.status.log >>
 
 lncRNApipe: AutoGenJobTime=Tue_Jan_26_10:20:14_2016 Run=1uzk7yVoHMcph Cufflinks assembly run has passed.

C<< lncRNApipe-test/run/cuffdiff_on_transcripts/status.log >>

 lncRNApipe: AutoGenJobTime=Tue_Jan_26_10:20:14_2016 Run=1uzk7yVoHMcph Cuffdiff run has passed.

C<< lncRNApipe-test/run4/lncRNApipe.postAssembly.status.log >>

 lncRNApipe: AutoGenJobTime=Tue_Jan_26_10:20:14_2016 Run=1uzk7yVoHMcph Post assembly pipeline run has passed.    
 
=head1 DESCRIPTION

lncRNApipe is a complete automated pipeline to:

=over 4

=item * Trim B<FASTQ> reads using Trimmomatic.

=item * Map reads using spliced read mapper, Tophat.

=item * Assemble transcripts using Cufflinks.

=item * Identify known non-coding RNAs and any putative novel non-coding RNAs based on reference annotation. 

=item * Use B<CPC> to estimate the coding potential of identified novel ncRNAs.

=item * Annotate novel non-coding RNAs using C<< cmscan >> from Infernal.

=item * Use B<I<RNAfold>> to calculate minimum free energy structure of the identified novel non-coding RNAs.

=item * Run Cuffdiff to identify differentially expressed known ncRNAs and novel ncRNAs.

=item * Optionally, run cuffdiff on all transcripts to identify differentially expressed transcripts as you would normally do with the L<Tuxedo protocol|http://www.nature.com/nprot/journal/v7/n3/full/nprot.2012.016.html>.

=back

The pipeline is very flexible and can be run in two ways: from B<I<assembly stage>> or from B<I<identification stage>> and maintains checkpoints at each stage so that you can resume from a failed run, if possible. 

=head2 ASSEMBLY STAGE

The most simplest way to run the complete pipeline is from the B<I<assembly stage>>.

This is where you supply the raw B<FASTQ> reads you got from your sequencing center, configure the parameters in a file called C<< params.yaml >> and run the jobs either or on a compute cluster or on your local work station. The assembly stage can be further broken down into following steps:

=head3 Filtering

lncRNApipe uses L<Trimmomatic|http://www.usadellab.org/cms/?page=trimmomatic> to trim reads. Any options you generally specify to Trimmomatic can be entered in the C<< params.yaml >> file. 

=head3 Mapping

Next, we run L<Tophat|https://ccb.jhu.edu/software/tophat/index.shtml> to perform spliced mapping of RNA-Seq reads. You can speicfy Tophat options using C<< tophat: >> parameter in C<< params.yaml >>. L<Sambamba|https://github.com/lomereiter/sambamba> is used to merge any replicate data before running Cufflinks.

=head3 Transcript Assembly

L<Cufflinks|http://cole-trapnell-lab.github.io/cufflinks/> is used to perform transcript assembly and you can specify the options using the C<< cufflinks: >> parameter in C<< params.yaml >>

=head2 IDENTIFICATION STAGE

In the identification stage, the pipeline will bind the functionality of the tools / scripts: C<< cuffcompare >>, C<< categorize_ncRNAs.pl >>, C<< get_unique_features.pl >>, C<< fetch_seq_from_ucsc.pl >>, C<< RNAfold >>, C<< Infernal >> and B<I<Coding Potential Calculator>> (C<< CPC >>). Transcriptome construction tools such as Cufflinks produces a set of assembled transcripts in GTF format. lncRNApipe uses this data in addition to known gene annotation to extract putative lncRNAs constructed by the ab initio assemblers. The pipeline relies on the proper transcript-exon features generated by the assembler and validates it against the known reference gene and non coding RNA information to identify putative novel lncRNAs. In brief, the pipeline steps in the B<I<identification stage>> are as follows:

=over 5

=item 1. Cuffcompare (lncRNApipe Option: --cuff or --cuffcompare)

The transcript assembly can be compared to known annotation of choice to classify them into different L<class codes|http://cole-trapnell-lab.github.io/cufflinks/cuffcompare/#transfrag-class-codes> using Cuffcompare. The assembled transcripts should be in GTF format. Cufflinks generates the output files in GTF format. If you are using other software such as Scripture, you can convert the output file in BED format into GTF using Scripture as:

 java -jar /path/to/scripture.jar -task toGFF -cufflinks -in scripture.out.bed -source SCRIPTURE -out scripture.out.gtf

To get help documentation about this module, run:

 perl lncRNApipe --h cuff

=item 2. categorize_ncRNAs.pl (lncRNApipe Option: --cat or --cat-ncRNAs)
    
lncRNApipe uses the tracking file (C<< *.tracking >>) produced by Cuffcompare, annotation data in gene prediction format and a list of supplied transcripts in GTF format to produce and categorize lncRNAs into different categories as mentioned in this L<paper|http://genome.cshlp.org/content/22/3/577.full>. In brief, the lncRNAs are classified into 5 categories: B<Long intergenic lncRNAs> (B<I<LincRNAs>>), B<Intronic contained lncRNAs> (B<I<Incs>>), B<Partially overlapping lncRNAs> (B<I<Poncs>>), B<Completely overlapping lncRNAs> (B<I<Concs>>) and B<Exonic overlaps> (B<I<LncRNAs with sense or antisense overlap with reference exon>>).

To get help documentation about this module, run:

 perl lncRNApipe --h cat

=item 3. get_unique_features.pl (lncRNApipe Option: --get or --get--uq-feat)
    
It then compares the putative list with supplied known lncRNAs in BED or GTF format to get features that do not overlap any known lncRNAs. To extract known lncRNAs from your assembled transcripts for downstream analysis, include C<< --known --extract >> with C<< --get >> option of lncRNApipe.

To get help documentation about this module, run:

 perl lncRNApipe --h get

=item 4. fetch_seq_from_ucsc.pl (lncRNApipe Option: --fetch or --fetch-seq)
    
This list is then used to fetch DNA sequence of those transcript sequences to determine their coding potential using CPC.
    
To get help documentation about this module, run:
    
 perl lncRNApipe --h fetch

=item 5. CPC.sh (lncRNApipe Option --cpc or --cpc)
    
In this step, the fetched FASTA sequences are used to determine the L<coding potential|http://cpc.cbi.pku.edu.cn/docs/quick_guide.jsp> and those that are flagged as B<noncoding> are used to create the final list of high confidence lncRNAs. This step may take a while to finish.

To get help documentation about this module, run:

 perl lncRNApipe --h cpc

=item 6. RNAfold (lncRNApipe Option --rna or --rnafold)

Here, lncRNApipe pipeline invokes C<< RNAfold >> program to calculate minimum free energy structure of the predicted non-coding RNA. This step may take a while to finish.
                                                                                                                                                                
To get help documentation about this module, run:
    
 perl lncRNApipe --h rna

=item 7. Infernal (lncRNApipe Option --inf or --infernal)

In the final step, lncRNApipe pipeline invokes C<< cmscan >> from B<Infernal> package to search Rfam databases for sturcture and sequence similarities to annotate the putative lncRNAs .

 
To get help documentation about this module, run:
    
 perl lncRNApipe --h inf

=back

=head1 RUNNING lncRNApipe

lncRNApipe can be run either completely via the configuration file a.k.a C<< params.yaml >> or the B<I<identification stage>> i.e the pipeline from C<< cuffcompare >> can be run independently without specifying the configuration file (C<< params.yaml >>), where you specify everything needed through the command line options, but we recommend that you use the configuration file for sake of clarity and simplicity.

The file C<< params.yaml >> contains all options required to run the pipeline from start to finish. Once you have entered the options as per your requirements, run the pipeline using the following command:

 perl lncRNApipe --conf params.yaml

=head1 params.yaml

C<< params.yaml >> is the configuration file, where you can specify the command line options for each of the modules of lncRNApipe to run the complete pipeline to go from B<I<reads to results>>. If you do not wish to run any of the modules, simply, disable them and all the lines following it (if, any) by prefixing it with C<< # >>. The comment lines in the C<< params.yaml >> generally start with C<< # >>. The options in the file C<< params.yaml >> follow a specific syntax. The parameters where you specify B<YES> or B<NO> generally end with a colon (C<< : >>).

Example:

 performTranscriptAssembly: YES

The parameters where you specify tools' options end with tool's name followed by tool's options with a dash prefix (C<< - >>).

Example:

 tophat:
  - --b2-sensitive

=head2 params.yaml's Options:

=over 4

=item outputDir: /data/konganti/FASTQ_RNAseq/new-lncRNApipe2

Specify output directory. In the example above, a new output directory called C<< new-lncRNApipe2 >> will be created at the mentioned path C<< /data/konganti/FASTQ_RNAseq >>

=item overwriteOutputDir: NO

Indicate, if we should overwrite the output directory if it already exists.

B<WARNING: THIS WILL REMOVE ANY FILES / DIRECTORIES>

=item performTranscriptAssembly: YES

Let lncRNApipe know if you intend to perform transcript assembly using tophat / cufflinks or just identify ncRNAs from already assembled transcripts.

=item CPUs: 10

Specify number of threads / CPUs to use where possible. If running on a grid, please also use job parameter specific to your cluster with C<< schedulerOpts: >> below.

=item scheduler: SGE

Specify scheduler type. Valid options are C<< PBS >>, C<< SGE >>, C<< LSF >>, C<< SLURM >> or C<< NONE >> to disable grid computing.

=item batchSubCmd: qsub

Mention batch submission command.
For example, for C<< LSF >>, it is C<< bsub >>, for C<< PBS >> or C<< SGE >>, it is C<< qsub >>, for C<< SLURM >>, it is C<< sbatch >>.

=item schedulerOpts:

Specify scheduler options on separate line specific to your job running environment.

********************* B<!! IMPORTANT !!> *****************************

Different clusters uses different job parameter names. For
example our cluster uses C<< num_threads >> as parameter name to
request number of CPUs in SGE. Some clusters may use
C<< num_cpu >>. Since it is difficult to guess, please provide
number of CPUs you want to use based on your grid environment
below, which is equal to C<< CPUs: >> option above. Yes, we know that
this is kind of redundant but it is necessary evil. What ever
job parameters you provide after the C<< - >> , they will appear
exactly in the job script.

B<IF IT IS NOT PROVIDED, THE JOB WILL RUN ON SINGLE CPU OR
MAY RUN ON MULTIPLE CPUs WHEN IT IS NOT SUPPOSED TO>.


Ex for PBS (job parameters start with a C<< PBS >> directive):

 PBS -V
 PBS -l nodes=1:ppn=16,walltime=24:00:00

Ex for C<< SGE >> (job parameters start with C<< $ >> sign):

 $ -N lncRNApipe
 $ -l num_threads=4

So, my scheduler is C<< SGE >>, the parameters on my cluster would look like:

 schedulerOpts:
  - $ -l mem_free=10G
  - $ -l num_threads=10

=item clusterOpts:

Mention any other lines that should be included in the job script.

Ex:

 clusterOpts:
  - module load java1.7.0 perl5.14.2

=item readType: FASTQ

Specify if your reads are in C<< FASTA >> or C<< FASTQ >> format. In the example above, reads are in C<< FASTQ >> format.

=item libType: SE

Specify if your reads are C<< SE >> (single-end only), C<< PE >> (paried-end only) or C<< MIXED >>.

=item sourceDB: UCSC

Specify if you want to use C<< ENSEMBL >> or C<< UCSC >> as source for annotation and do not want to use C<< useThisAnnotation: >>. B<PLEASE MAKE SURE> that you are using the same C<< sourceDB >> for tophat alignments, i.e. bowtie indexes created from the same C<< sourceDB >> for the same assembly version. As downloading genome indices on-the-fly is time consuming and since many users may have genome indices installed for various NGS analysis anyways, we leave it to you to provide B<CORRECT> genome index below in tophat and cufflinks options' configuration.

I<Currently> C<< sourceDB: >> I<is required to be either> C<< ENSEMBL >> I<or> C<< UCSC >> I<or> C<< CUSTOM >>.

=item species: rn4

Choose assembly version if you do not want to use C<< useThisAnnotation: >> so that we can download up-to-date annotation on the fly. You can choose to supply your own annotation file for consistency below. C<< ENSEMBL >> and C<< UCSC >> represents species name differently in the URLs. To view species names for C<< ENSEMBL >> do:

 perl lncRNApipe --list ENSEMBL

Go to https://genome.ucsc.edu/FAQ/FAQreleases.html#TOP to view UCSC version names.
For example, at C<< UCSC >>, for mouse, it is C<< mm9 >> or C<< mm10 >>, for rat, it is C<< rn5 >> or C<< rn6 >> etc...

In case of B<I<sourceDB: CUSTOM>>, you can use species name of your choice. Ex: C<< species: cotton >>.

=item useThisAnnotation: /data/ref_annotation/rn4_UCSC/genes.gtf

If you want to use your own annoation file, provide full path to the annotation file of your choice. This option overrides C<< species: >> options above. Again, B<PLEASE MAKE SURE>, you are providing the same genome index from the same source annotation file. In the example below, C<< bowtieGenomeIndex >> is C<< rn4 >> genome index created from C<< FASTA >> files from C<< UCSC >>.

=item reads: 

Provide Unix path to directory where the read files are located and also provide read file names that are present in that directory. If your data is just C<< SE >>, then disable C<< r2: >> below by prefixing it with a C<< # >>. Separate replicates of sample by a comma. Separate different samples by a C<< | >>.

B<PLEASE MAKE SURE THE READS ARE IN ORDER. DO NOT MIX AND MATCH READ ORDERS. WE HAVE NO WAY OF KNOWING WHICH READ FILE IS _1 or _2>.

In the example below, I have 8 samples and each sample has about 5-6 replicates. The read library is C<< SE >>.

 reads:
  readsDir: /data/konganti/FASTQ_RNAseq/reads
  r1: cca-2111.fastq,cca-2108.fastq,cca-2107.fastq,cca-1103.fastq,cca-2106.fastq|fpa-2410.fastq,fpa-2409.fastq,fpa-2408.fastq,fpa-1405.fastq,fpa-1403.fastq,fpa-1402.fastq|cpa-2210.fastq,cpa-2209.fastq,cpa-2207.fastq,cpa-1205.fastq,cpa-1204.fastq,cpa-1202.fastq|fca-2311.fastq,fca-2306.fastq,fca-1305.fastq,fca-1303.fastq,fca-1302.fastq,fca-1301.fastq|ccs-2506.fastq,ccs-2504.fastq,ccs-2505.fastq,ccs-1503.fastq,ccs-1502.fastq,ccs-1501.fastq|cps-2605.fastq,cps-2606.fastq,cps-2604.fastq,cps-1603.fastq,cps-1601.fastq,cps-1602.fastq|fcs-2706.fastq,fcs-2705.fastq,fcs-1703.fastq,fcs-2704.fastq,fcs-1702.fastq,fcs-1701.fastq|fps-2806.fastq,fps-2805.fastq,fps-2804.fastq,fps-1803.fastq,fps-1802.fastq,fps-1801.fastq
  # r2:

=item trimmomatic:

If you want to use Trimmomatic to trim reads, then provide TRIMMOMATIC options. TRIMMOMATIC provides the following adapter files: B<I<NexteraPE-PE.fa>>, B<I<TruSeq2-PE.fa>>, B<I<TruSeq2-SE.fa>>, B<I<TruSeq3-PE-2.fa>>, B<I<TruSeq3-PE.fa>> and B<I<TruSeq3-SE.fa>>. These adapter files are COPYRIGHTED by ILLUMINA and are public.

No need to provide C<< -threads >>, as it will be handled by lncRNApipe.

Ex:

 trimmomatic:
  - ILLUMINACLIP:TruSeq3-SE.fa:2:30:10
  - LEADING:20
  - TRAILING:20
  - SLIDINGWINDOW:5:20
  - MINLEN:25

=item genomeFasta: /data/ref_fasta/rn4_UCSC/genome.fa

Provide full path to genome C<< FASTA >> file. In the example above, it is a multi C<< FASTA >> for C<< rn4 >> downloaded from C<< UCSC >>.

=item bowtieGenomeIndex: /data/ref_indexes/bowtie2/rn4_UCSC/genome

Provide bowtie genome index. B<PLEASE MAKE SURE> that you are using the same genome indices for the C<< sourceDB: >>  mentioned above. Do not use C<< UCSC >> genome indices if you requested C<< ENSEMBL >> above in C<< sourceDB: >> or vice versa. In the example above, I am using genome indices for C<< rn4 >> created from C<< /data/ref_fasta/rn4_UCSC/genome.fa >> with C<< bowtie2-build >> command.

=item tophat:

In the example below, it is assumed that you have already created a transcriptome index. If you have not created one, go through tophat manual on how to L<just create transcriptome index|https://ccb.jhu.edu/software/tophat/manual.shtml>. If you use C<< --trancriptome-index >> below and the index does not exist, it will keep overwriting while the jobs are running.

No need to provide C<< FASTQ >> files, as they will be handled by lncRNApipe.

No need to provide C<< -o >>, as it will be handled by lncRNApipe.

No need to provide C<< -p >>, as it will be handled by lncRNApipe.

Ex:

 tophat:
  - --b2-sensitive
  - --transcriptome-index=/data/konganti/FASTQ_RNAseq/transcriptome_index/rn4
  - --no-coverage-search

=item cufflinks:

Provide cufflinks options and also B<PLEASE MAKE SURE> you provide the same reference FASTA for the C<< sourceDB >> you want to use in case of bias correction.

No need to provide C<< -g >>, as it will be handled by lncRNApipe.

No need to provide C<< -o >>, as it will be handled by lncRNApipe.

No need to provide C<< -p >>, as it will be handled by lncRNApipe.

No need to provide input files, as they will be handled by lncRNApipe.

Ex:

 cufflinks:
  - -u
  - -b /data/ref_fasta/rn4_UCSC/genome.fa

=item cuffcompare:

Provide cuffcompare options.

********************* B<!! IMPORTANT !!> *****************************

If you only want to run lncRNApipe without the transcript B<I<assembly stage>>, then provide assembled transcripts in GTF format, otherwise, no options are needed.
# 

No need to provide C<< -r >>, as it will be handled by lncRNApipe.

Provide C<< -i transcript_assembly_list.txt >> if you did not run B<I<assembly stage>>, where C<< transcript_assembly_list.txt >> contains full path to assembled transcript files.

Ex:

 cuffcompare:
  - -i /data/cufflinks/assembly_list.txt

=item categorize_ncRNAs:

Provide C<< categorize_ncRNAs.pl >>'s options. See C<< perl lncRNApipe --h cat >> for description of options.

No need to provide C<< -annot >> option as it is handled by lncRNApipe.

Ex:

 categorize_ncRNAs:
  - -sample-names "cca,fpa,cpa,fca,ccs,cps,fcs,fps"
  - -len 200
  - -min-exons 1
  - -ov 80
  - -inc

=item get_unique_features:

Provide C<< get_unique_features.pl >>'s options. Generally only C<< -ov >> is required in either case of C<< [performTranscriptAssembly: YES] >> or C<< [performTranscriptAssembly: NO] >>.

When you supply your own known ncRNAs file to compare against with C<< -sf >>, then you B<MUST> also specify it's file format (Ex: gtf or bed) with
C<< -sff >> option.
 
See C<< perl lncRNApipe --h get >> for description of options.

Ex:

 get_unique_features:
  - -ov 10
  - -sf /data/G_hirsutum/G_hirsutum_annotation.gff
  - -sff gtf

=item runRNAfold:

By, default, C<< RNAfold >> is not run since it is very slow.
It is generally recommended to generate C<< RNAfold >> plots
based on the transcript of your interest after you have
investigated the results, but you can still enable it
in the pipeline by uncommenting C<< runRNAfold: YES >> to
run C<< RNAfold >>  with default options.

To pass command line options to RNAfold, define it
after line C<< RNAfold: >>

Mention any other option other than C<< -p >> and C<< --noPS >> as they
are automatically handled by lncRNApipe.

See C<< perl lncRNApipe --h rna >> for description of options.

Ex:

 runRNAfold: YES
 RNAfold:
  - --circ

=item runcmscan:

Provide options to C<< cmscan >>. Running C<< cmscan >> with default options provides good matches in most cases, but in any case you want to add extra options, do it here.

To run C<< cmscan >> with default options, use C<< runcmscan: YES >>.

Add additional options you want to pass to C<< cmscan >> after line C<< cmscan: >>. Provide any options other than C<< -o >>, C<< --tblout >> and C<< --cpu >> as they are automatically handled by lncRNApipe.

See C<< "perl lncRNApipe --h inf >> for description of options.

Ex:

 runcmscan: YES
 cmscan:
 # - -E 9.0

=item cuffmerge:

Provide cuffmerge options. If you have replicates, final predicted lncRNAs will be merged.

No need to provide C<< -s >>, as it will be handled by lncRNApipe.

No need to provide C<< -g >>, as it will be handled by lncRNApipe.

Ex:

 cuffmerge:
  - --min-isoform-fraction 0.05
 
=item cuffdiff:

Provide C<< cuffdiff >> options if you want to run differential expression
tests between known ncRNAs and between novel ncRNAs in your samples.

Normally, C<< cuffdiff >> is only run on identified known and novel ncRNAs.
If you want to run C<< cuffdiff >> on all transcripts, i.e to identify
differentially expressed transcripts (end of typical tuxedo pipeline),
then change C<< runCuffdiffForAllTranscripts >> to C<< YES >>. 

If you have mentioned C<< -sample-names >> above in C<< categorize_ncRNAs: >>,
no need to mention C<< -L >>, else provide C<< -L >> option here.

No need to provide C<< -o >>, as it will be handled by lncRNApipe.

No need to provide C<< -p >>, as it will be handled by lncRNApipe.

No need to provide input files, if you have run tophat, cufflinks above.

If C<< performTranscriptAssembly >> is C<< NO >>, then provide your own BAM files here prefixed by C<< -bam >> option. Separate replicate BAM files with comma as you generally do with C<< cuffdiff >> command.

Ex:

 runCuffdiffForAllTranscripts: YES
 cuffdiff:
  - -u
  - -b /data/ref_fasta/rn4_UCSC/genome.fa
  # - -bam /data/aligned_rn4_UCSC/sample1/rep1.bam,/data/aligned_rn4_UCSC/sample1/rep2.bam /data/aligned_rn4_UCSC/sample2/rep1.bam,/data/aligned_rn4_UCSC/sample2/rep2.bam

=back

=head1 CAVEATS

The pipeline script uses a lot of inherent B<GNU> core utilities and has been only tested in B<BASH> shell. Please use absolute full B<PATH> names.

=over 5

=item * Instead of using:

  lncRNApipe --run ./lncRNApipe_output ...

Use: 

  lncRNApipe --run /data/lncRNApipe_output ...

=item * If pipeline setup fails due to C<< XML::Parser >> module, you need to install XML parser C libraries. 

On Ubuntu / Debian based Linux distributions, as C<< root >> user, do:

    apt-get install libexpat1 libexpat1-dev
                    
On RedHat / Fedora / CentOS based Linux distributions, as C<< root >> user do:

    yum install expat expat-devel

=item * Please make sure your C<< $SHELL >> is C<< /bin/bash >>. Do:

    echo $SHELL

If it is not C<< /bin/bash >>, use the command C<< chsh -s /bin/bash >> to change your login shell. You need to log out and log back in for default login shell to take effect.

=item * On newer Ubuntu distributions of Linux, even though C<< $SHELL >> shows C<< /bin/bash >>, the shell in fact points to C<< /bin/dash >>. To change that, follow these L<instructions|https://justinconover.wordpress.com/2012/05/14/ubuntu-changing-dash-to-bash>.

=back

=head1 OUTPUT

The final output is a putative list of annotated lncRNAs in GTF format that can be directly uploaded as custom tracks to Genome Browsers, such as UCSC etc... and predicted secondary structures by RNAfold. 

=over 5

=item * Output from C<< trimmomatic.jar >> is stored in directory called B<trimmomatic>. Replicate data (if any) is maintained separately inside B<trimmomatic> directory. A C<< status.log >> file inside B<trimmomatic> directory contains status information for each run.

=item * Output from C<< tophat >> is stored in directory called B<tophat>. Replicate data (if any) is maintained separately inside B<tophat> directory. A C<< status.log >> file inside B<tophat> directory contains status information for each run.

=item * Output from C<< cufflinks >> is stored in directory called B<cufflinks>. Replicate data (if any) is maintained separately inside B<cufflinks> directory. A C<< status.log >> file inside B<cufflinks> directory contains status information for each run.

=item * Output from C<< cuffcompare >> is stored in the directory called B< cuffcompare >. lncRNApipe uses C<< lncRNApipe_cuffcmp.tracking >> file from this folder for the next module.

=item * Output from C<< categorize_ncRNAs.pl >> is stored in the directory called B<categorize_ncRNAs>. lncRNApipe uses files ending with suffix C<< .putative.class.lncRNAs.gtf >> for the next module.

=item * Output from C<< get_unique_features.pl >> output is stored in the directory called B<get_unique_features>. lncRNApipe uses files ending with suffix C<< .putative.class.lncRNAs.unique.gtf >> or C<< .putative.class.lncRNAs.known.gtf  >> for the next module.

=item * Output from C<< fetch_seq_from_ucsc.pl >> is stored in the directory called B<fetch_seq_from_ucsc>. lncRNApipe uses these FASTA seqeunce files to run CPC, RNAfold and Infernal modules. The file ending in suffix C<< .noncoding.FASTA >> is used for the next modules.

=item * C<< CPC >>predictions are stored in a directory called B<CPC>.

=item * The final result files are stored in a directory called B<lncRNApipe.final> and have a suffix B<.final.gtf>.

=item * The C<< RNAfold >> plots are stored in directories inside B<lncRNApipe.final> directory ending in suffix C<< .final.RNAfold >>.

=item * The result files from C<< cmscan >> (B<Infernal>) are stored in directories inside B<lncRNApipe.final> directory ending with suffix C<< .infernal >>. The file ending in suffix C<< .allInfernalHits.gtf >> contains all RNA hmm and cm model matches from C<< cmscan >> (B<Infernal>) and the best hit is applied to file ending in suffix C<< .final.gtf >> based on the sequence coverage (C<< --coverage-infernal >>) filter requested.

=item * Output directory B<cuffmerge_novel_ncRNAs> contains files from merged novel ncRNAs. C<< merged.gtf >> file from this directory is used to get information about differentially expressed novel ncRNAs.

=item * Output directory B<cuffmerge_known_ncRNAs> contains files from merged known ncRNAs. C<< merged.gtf >> file from this directory is used to get information about differentially expressed known ncRNAs.

=item * Output directory B<cuffdiff_novel_ncRNAs> contains files from C<< cuffdiff >> run on novel ncRNAs.

=item * Output directory B<cuffdiff_known_ncRNAs> contains files from C<< cuffdiff >> run on known ncRNAs.

=item * Output directory B<job_scripts_Day_Month_Date_Hour_Min_Sec_Year> contains all the job scripts automatically generated by lncRNApipe.

=back

The pipeline has the ability to run each of these individual modules if any of them fail during the initial run.

=head2 Start the pipeline without using the configuration file:

=over 5

=item * Run the complete pipeline without using the configuration file through command line options:

 perl lncRNApipe --run /data/lncRNApipe/ --cuff '-r /data/projects/mm10/macrophages/rna-seq/cuffcompare.m0.m1.m2_vs_ensembl_ref_known/refSeq_UCSCKnownGenes_Ensemble.gtf -s /data/ref_fasta/mm10_UCSC/whole_genome.fa /data/projects/mm10/macrophages/rna-seq/m0/cufflinks/transcripts.gtf /data/projects/mm10/macrophages/rna-seq/m1/cufflinks/transcripts.gtf /data/projects/mm10/macrophages/rna-seq/m2/cufflinks/transcripts.gtf' -cat '-clean -overlap 80 -len 200 -max-len 10000 -min-exons 1 -fpkm 2 -antisense -sample-names "M0,M1,M2"' --get '-sf /data/projects/mm10/macrophages/ncrna/known_ref_lncRNAs/mm10_ncRNA.bed' --fetch --cpc --inf

=item * Run B<I<categorize_ncRNAs>> module of the pipeline:
    
 perl lncRNApipe --run /data/lncRNApipe/ --cat '-clean -overlap 80 -len 200 -max-len 10000 -min-exons 1 -fpkm 2 -annotation /data/projects/mm10/macrophages/ncrna/2lncRNA/allGenes.txt -antisense -sample-names "M0,M1,M2" /data/projects/mm10/macrophages/rna-seq/m0/cufflinks/transcripts.gtf /data/projects/mm10/macrophages/rna-seq/m1/cufflinks/transcripts.gtf /data/projects/mm10/macrophages/rna-seq/m2/cufflinks/transcripts.gtf'

=item * Run B<I<get_unique_features>> module of the pipeline to extract novel lncRNAs:
    
 perl lncRNApipe -run /data/lncRNApipe --get '-sf /data/projects/mm10/macrophages/ncrna/known_ref_lncRNAs/mm10_ncRNA.bed'

=item * Run B<I<get_unique_features module>> of the pipeline to extract known lncRNAs:
    
 perl lncRNApipe --run /data/lncRNApipe --get '--known --extract -sf /data/projects/mm10/macrophages/ncrna/known_ref_lncRNAs/mm10_ncRNA.bed'

=item * Run B<I<fetch_unique_features module>> of the pipeline:

 perl lncRNApipe --run /data/lncRNApipe --fetch '-local /data/ref_fasta/mm10_UCSC/genome.fa'

=item * Run B<I<CPC>> module of the pipeline:

 perl lncRNApipe --run /data/lncRNApipe --cpc

=item * Run B<I<RNAfold>> module of the pipeline:

 perl lncRNApipe --run /data/lncRNApipe --rna

=item * Run B<I<Infernal>> module of the pipeline:

 perl lncRNApipe --run /data/lncRNApipe --inf

=back

=head1 OPTIONS

lncRNApipe takes the following arguments:

=over 4

=item --v or --version (Optional)
    
Displays version information and quits.

=item --d or --no-update-chk (Optional)
    
Disable software update check.

=item --h or --help (Optional)
    
Displays this helpful message.

=item --setup or --setup
    
Try to setup the pipeline with all its dependencies.

=item --setup-compiler

If any of the perl module installation fails during the setup process, change
the compiler that works with your machine state.

Ex:

 perl lncRNApipe --setup --setup-compiler CC=icpc

=item --run

Run the lncRNApipe pipeline with output directory supplied as option.

Ex: 
 
 perl lncRNApipe -run /home/konganti/lncRNApipe_output ...

=item --cuff or --cuffcompare

Run the C<< cuffcompare >> module with supplied options.

=item --cat or --cat-ncRNAs

Run the C<< categorize_ncRNAs.pl >> module with supplied options.

=item --get or --get-uq-feat

Run the C<< get_unique_features.pl >> module with supplied options.

=item --fetch or --fetch-seq

Run the C<< fetch_seq_from_ucsc.pl >> module with supplied options.
Using C<< --fetch >> without any options will try and use local reference FASTA
mentioned with C<< --cuffcompare >> option.

=item --skip-get (--fetch-seq option required)

Run the C<< fetch_seq_from_ucsc.pl >> module without running C<< get_unique_features.pl >> module.
In some cases, you may not have a file of known non-coding RNAs. In such cases,
you can skip C<< get_unique_features.pl >> module, and directly fetch FASTA sequences for
features from C<< --cat-ncRNAs >> module.

=item --cpc or --cpc

Run the C<< CPC >> module. No options are required.

=item --cpc-strand-reverse (Optional)

This option will direct CPC 2.0 to search the query strand in both forward and reverse directions.

Default: Only forward strand is searched.

=item --skip-cpc

Skip runnning C<< CPC >> altogether. Use this option, if you think CPC is flagging a lot of
your transcripts as B<I<coding>> and instead rely only on Infernal search results.

=item --skip-cpc-core

Skip runnning core C<< CPC >> process once you know you have output from C<< CPC >>.
This option can be used when lncRNApipe fails for some reason after
C<< CPC >> has finished running but unable to continue forward.

=item --rna or --rnafold

Run C<< RNAfold >> module of the pipeline. No options required

=item --skip-rnafold-core

Skip runnning core C<< RNAfold >> process once you know you have output from C<< RNAfold >>.
This option can be used when you want lncRNApipe to generate plots based on
output from C<< RNAfold >> which should have completed successfully.

=item --inf or --infernal

Run Infernal module of the pipeline. No options required

=item --skip-cmscan-core

Skip runnning C<< cmscan >> process once you know you have output from a successful 
C<< cmscan >> run. This option can be used when you want lncRNApipe to extract 
annotation from infernal and attempt to annotate putative novel lncRNAs.

=item --cov-inf or --coverage-infernal

Only annotate final putative lncRNAs which have C<< cmscan >> match over this much percentage of sequence.

Default: 10

=item --cpu

lncRNApipe will attempt to run multiple processes on this may CPU cores.
Mentioning number of CPUs equal to or more than number of assembled 
transcript files is strongly encouraged.

=item --send-run-report

lncRNApipe will send your log file. For this to work, you need to save the output of the pipeline to
a log file. 

Ex:

 perl lncRNApipe --run /data/lncRNApipe/ \
                 --cuffcmp '-r annotation.gtf -s genome.fa transcripts1.gtf transcripts2.gtf' \
                 --cat-ncRNAs '-sample-names "M1,M2" -ov 80 -fpkm 2 -len 200 -max-len 10000 -min-exons 1 -antisense" \
                 --fetch-seq '-db mm10' \
                 --cpc \
                 --rna \
                 --inf  &> lncRNAPipe.run.log 

and then, if the run fails or if you wish to discuss other issues. Use:

 perl lncRNApipe --send-run-report '-email your_email@gmail.com -log lncRNApipe.run.log -m "I cannot run lncRNApipe because lorem ipsum ...."'

=item --dont-wait

Initially, when designing the pipeline, using C<< Schedule::DRMAAc >> was considered to submit jobs via DRMAA API in grid computing environment. I later found that C<< drmaa.h >> is not present on all cluster installations and cluster admins can install DRMAA API on request, but it defeats the purpose of simply installing the pipeline and just running the jobs. I then used regex to parse the output of the batch submission command and create dependency chain from it. It works on most of the cluster installations where the scheduler is either SGE, PBS, SLURM or LSF. Using C<< --dont-wait >> option will not wait for user confirmation to verify that the program has parsed the job IDs correctly. When C<< --dont-wait >> option is not used, the program will prompt for user to verify that the job IDs gathered are in fact correct. Yes, this is rudimentary, but as I explained above, it gets the job done.

=item --kill

Kill jobs. If you have used either grid submission or not used grid submission, all the job ids or PIDs will be present in 3 files: B<job_scripts_Day_Month_Date_Hour_Min_Sec_Year>/C<< job_IDs_tophat.RUNID >>, B<job_scripts_Day_Month_Date_Hour_Min_Sec_Year>/C<< job_IDs_cufflinks.RUNID >> and B<job_scripts_Day_Month_Date_Hour_Min_Sec_Year>/C<< job_IDs_lncRNApipe_postAssembly.RUNID >>. If you want to kill any jobs for any reason do:

 perl lncRNApipe --conf params.yaml --kill job_scripts.Wed_Jun_24_11_30_44_2015/job_IDs_tophat.2CphrqPLqFdCs

If you want to kill jobs from multiple job IDs' files, do:

 perl lncRNApipe --conf params.yaml --kill job_scripts.Wed_Jun_24_11_30_44_2015/job_IDs_tophat.2CphrqPLqFdCs --kill job_scripts.Wed_Jun_24_11_30_44_2015/job_IDs_cufflinks.2CphrqPLqFdCs --kill job_scripts.Wed_Jun_24_11_30_44_2015/job_IDs_lncRNApipe_postAssembly.2CphrqPLqFdCs

=item --show-counts

Shows lncRNA counts for requested files. If for any reason, you want to get just the counts of identified lncRNAs from lncRNApipe, use this option. Ex:

 perl lncRNApipe --show-counts lncRNApipe.final/transcripts.1.gtf --show-counts lncRNApipe.final/transcripts.2.gtf

=back

=head1 AUTHOR

Kranti Konganti, E<lt>konganti@tamu.eduE<gt>.

=head1 COPYRIGHT

This program is distributed under the Artistic License 2.0.

=head1 DATE

Oct-04-2019

=cut
